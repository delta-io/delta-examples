{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64af9d8-f95c-497e-a3d9-ccaa4e0f95d5",
   "metadata": {},
   "source": [
    "## Python deltalake 0.8.1 Release\n",
    "\n",
    "The 0.8.1 version of Python deltalake adds overwriting partitions. In the `write_deltalake` function you can use `mode='overwrite'` in combination with `partition_filters` to overwrite part of a Delta Lake table. This can be a single partition or multiple partitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e2f912-d754-4c2d-9445-be7e12ef7114",
   "metadata": {},
   "source": [
    "As an example, let's say we have a table partitioned by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aab236f-c3c4-4e12-a4e9-5ef9fa6e16ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_date</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>-0.363669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1.821875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1.648210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>-1.672757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>-1.378446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>-0.559470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-0.190479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1.431008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-0.188100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  observation_date    values\n",
       "0       2023-01-02 -0.363669\n",
       "1       2023-01-02  1.821875\n",
       "2       2023-01-02  1.648210\n",
       "3       2023-01-03 -1.672757\n",
       "4       2023-01-03 -1.378446\n",
       "5       2023-01-03 -0.559470\n",
       "6       2023-01-01 -0.190479\n",
       "7       2023-01-01  1.431008\n",
       "8       2023-01-01 -0.188100"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import pandas as pd\n",
    "from deltalake import DeltaTable, write_deltalake\n",
    "\n",
    "nrows = 9\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"observation_date\": np.repeat(\n",
    "            [date(2023, 1, 1), date(2023, 1, 2), date(2023, 1, 3)], nrows / 3\n",
    "        ),\n",
    "        \"values\": numpy.random.normal(size=nrows),\n",
    "    }\n",
    ")\n",
    "table_path = \"tables/observations\"\n",
    "write_deltalake(\n",
    "    table_path,\n",
    "    data,\n",
    "    partition_by=[\"observation_date\"],\n",
    "    mode=\"overwrite\",\n",
    ")\n",
    "DeltaTable(table_path).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9abafd-b02c-4b79-8f94-872ac511d098",
   "metadata": {},
   "source": [
    "If we have new data to replace the observations on 2023-01-03, we can overwrite the partition with new data by passing the DNF filter `[(\"observation_date\", \"=\", \"2023-01-03\")]` to `partition_filters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e77bad59-2560-4182-be4c-75fb467b0656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_date</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>-0.363669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1.821875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1.648210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-0.190479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1.431008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-0.188100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>8.542938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>9.833954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>10.937024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  observation_date     values\n",
       "0       2023-01-02  -0.363669\n",
       "1       2023-01-02   1.821875\n",
       "2       2023-01-02   1.648210\n",
       "3       2023-01-01  -0.190479\n",
       "4       2023-01-01   1.431008\n",
       "5       2023-01-01  -0.188100\n",
       "6       2023-01-03   8.542938\n",
       "7       2023-01-03   9.833954\n",
       "8       2023-01-03  10.937024"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows = 3\n",
    "new_data = pd.DataFrame(\n",
    "    {\n",
    "        \"observation_date\": np.repeat(date(2023, 1, 3), nrows),\n",
    "        \"values\": numpy.random.normal(size=nrows) + 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "write_deltalake(\n",
    "    table_path,\n",
    "    new_data,\n",
    "    mode=\"overwrite\",\n",
    "    partition_filters=[(\"observation_date\", \"=\", \"2023-01-03\")],\n",
    ")\n",
    "DeltaTable(table_path).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc076c0-5256-43f0-a5c8-0223c11ab6e0",
   "metadata": {},
   "source": [
    "Now we have the new values just in the 2023-01-01 partition.\n",
    "\n",
    "You can also use partition writing to create *new* partitions. This makes the operation [idempotent](https://en.wikipedia.org/wiki/Idempotence), which is a very useful property in data engineering. If an overwrite partition is accidentally run twice for the same partition, it won't create duplicate data. This is a property relied on in systems like Airflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b6001c-77fb-4220-95dc-4b4b3f5e9b9f",
   "metadata": {},
   "source": [
    "To make sure the write is safe, this method will check your data to make sure it only within the partitions you are overwriting. This makes sure no one accidentally corrupts the table. For example, if we tried to save that same data for 2023-01-03 into the partition for 2023-01-04, we will get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2abf3905-4ea5-41a7-8334-db84754d7df0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data should be aligned with partitioning. Data contained values for partition observation_date=2023-01-03",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwrite_deltalake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobservation_date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2023-01-04\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/notebooks/lib/python3.10/site-packages/deltalake/writer.py:293\u001b[0m, in \u001b[0;36mwrite_deltalake\u001b[0;34m(table_or_uri, data, schema, partition_by, filesystem, mode, file_options, max_open_files, max_rows_per_file, min_rows_per_group, max_rows_per_group, name, description, configuration, overwrite_schema, storage_options, partition_filters)\u001b[0m\n\u001b[1;32m    287\u001b[0m         batch_iter \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    289\u001b[0m     data \u001b[38;5;241m=\u001b[39m RecordBatchReader\u001b[38;5;241m.\u001b[39mfrom_batches(\n\u001b[1;32m    290\u001b[0m         schema, (validate_batch(batch) \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batch_iter)\n\u001b[1;32m    291\u001b[0m     )\n\u001b[0;32m--> 293\u001b[0m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbasename_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcurrent_version\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muuid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muuid4\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;130;43;01m{{\u001b[39;49;00m\u001b[38;5;124;43mi\u001b[39;49m\u001b[38;5;130;43;01m}}\u001b[39;49;00m\u001b[38;5;124;43m.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# It will not accept a schema if using a RBR\u001b[39;49;00m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRecordBatchReader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_visitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexisting_data_behavior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverwrite_or_ignore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_open_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_open_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_rows_per_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows_per_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_rows_per_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_rows_per_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_rows_per_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows_per_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     _write_new_deltalake(\n\u001b[1;32m    313\u001b[0m         table_uri,\n\u001b[1;32m    314\u001b[0m         schema,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    321\u001b[0m         storage_options,\n\u001b[1;32m    322\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/notebooks/lib/python3.10/site-packages/pyarrow/dataset.py:998\u001b[0m, in \u001b[0;36mwrite_dataset\u001b[0;34m(data, base_dir, basename_template, format, partitioning, partitioning_flavor, schema, filesystem, file_options, use_threads, max_partitions, max_open_files, max_rows_per_file, min_rows_per_group, max_rows_per_group, file_visitor, existing_data_behavior, create_dir)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot specify a schema when writing a Scanner\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    996\u001b[0m     scanner \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m--> 998\u001b[0m \u001b[43m_filesystemdataset_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscanner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasename_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_partitions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_visitor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexisting_data_behavior\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_open_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows_per_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_rows_per_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows_per_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_dir\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/notebooks/lib/python3.10/site-packages/pyarrow/_dataset.pyx:3016\u001b[0m, in \u001b[0;36mpyarrow._dataset._filesystemdataset_write\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/notebooks/lib/python3.10/site-packages/deltalake/writer.py:290\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m         batch_iter \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    289\u001b[0m     data \u001b[38;5;241m=\u001b[39m RecordBatchReader\u001b[38;5;241m.\u001b[39mfrom_batches(\n\u001b[0;32m--> 290\u001b[0m         schema, (\u001b[43mvalidate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batch_iter)\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    293\u001b[0m ds\u001b[38;5;241m.\u001b[39mwrite_dataset(\n\u001b[1;32m    294\u001b[0m     data,\n\u001b[1;32m    295\u001b[0m     base_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[1;32m    309\u001b[0m )\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/notebooks/lib/python3.10/site-packages/deltalake/writer.py:276\u001b[0m, in \u001b[0;36mwrite_deltalake.<locals>.validate_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    273\u001b[0m checker\u001b[38;5;241m.\u001b[39mcheck_batch(batch)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m partition_filters:\n\u001b[0;32m--> 276\u001b[0m     \u001b[43mcheck_data_is_aligned_with_partition_filtering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "File \u001b[0;32m~/mambaforge/envs/notebooks/lib/python3.10/site-packages/deltalake/writer.py:267\u001b[0m, in \u001b[0;36mwrite_deltalake.<locals>.check_data_is_aligned_with_partition_filtering\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    261\u001b[0m     partition \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_partitions\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m partition \u001b[38;5;129;01min\u001b[39;00m existed_partitions\n\u001b[1;32m    263\u001b[0m ):\n\u001b[1;32m    264\u001b[0m     partition_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m partition_map\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    266\u001b[0m     )\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData should be aligned with partitioning. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData contained values for partition \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpartition_repr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Data should be aligned with partitioning. Data contained values for partition observation_date=2023-01-03"
     ]
    }
   ],
   "source": [
    "write_deltalake(\n",
    "    table_path,\n",
    "    new_data,\n",
    "    mode=\"overwrite\",\n",
    "    partition_filters=[(\"observation_date\", \"=\", \"2023-01-04\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b6e0f0-feaf-42e0-b41a-294808f666c9",
   "metadata": {},
   "source": [
    "You can also overwrite more than one partition at a time, since `partition_filters` supports inequality conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e5a98a0-314b-46e1-bf86-31377e991f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_date</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-0.190479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1.431008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-0.188100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>-5.516889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>-5.271391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>-6.383807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>-3.205016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>-4.892187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>-6.186804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>-6.719393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>-4.467193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>-6.571248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>-2.436545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>-4.061226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>-3.851402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   observation_date    values\n",
       "0        2023-01-01 -0.190479\n",
       "1        2023-01-01  1.431008\n",
       "2        2023-01-01 -0.188100\n",
       "3        2023-01-02 -5.516889\n",
       "4        2023-01-02 -5.271391\n",
       "5        2023-01-02 -6.383807\n",
       "6        2023-01-02 -3.205016\n",
       "7        2023-01-04 -4.892187\n",
       "8        2023-01-04 -6.186804\n",
       "9        2023-01-04 -6.719393\n",
       "10       2023-01-04 -4.467193\n",
       "11       2023-01-03 -6.571248\n",
       "12       2023-01-03 -2.436545\n",
       "13       2023-01-03 -4.061226\n",
       "14       2023-01-03 -3.851402"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows = 12\n",
    "new_data = pd.DataFrame(\n",
    "    {\n",
    "        \"observation_date\": np.repeat(\n",
    "            [date(2023, 1, 2), date(2023, 1, 3), date(2023, 1, 4)], nrows / 3\n",
    "        ),\n",
    "        \"values\": numpy.random.normal(size=nrows) - 5,\n",
    "    }\n",
    ")\n",
    "\n",
    "write_deltalake(\n",
    "    table_path,\n",
    "    new_data,\n",
    "    mode=\"overwrite\",\n",
    "    partition_filters=[(\"observation_date\", \">=\", \"2023-01-02\")],\n",
    ")\n",
    "DeltaTable(table_path).to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

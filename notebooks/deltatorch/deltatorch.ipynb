{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deltatorch Example\n",
    "This notebook briefly demonstrates how to use the [deltatorch](https://github.com/delta-incubator/deltatorch) python library to use `DeltaLake` tables as a data source for model training using PyTorch. The deltatorch library allows users to create a PyTorch `DataLoader` from a DeltaLake dataset.\n",
    "\n",
    "In this end-to-end example, we'll create a `DataLoader` from a Delta Lake table containing the MNIST dataset, and use it to train a PyTorch CNN model. The `deltatorch` library enables creating PyTorch `DataLoader`s directly from Delta Lake tables, avoiding any conversion to Pandas/NumPy. This allows efficient, scalable data loading from Delta Lake into PyTorch.\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/delta-incubator/deltatorch\n",
      "  Cloning https://github.com/delta-incubator/deltatorch to /private/var/folders/m_/nbhhpg550yl539yhlgch8qqr0000gp/T/pip-req-build-xss6efwr\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/delta-incubator/deltatorch /private/var/folders/m_/nbhhpg550yl539yhlgch8qqr0000gp/T/pip-req-build-xss6efwr\n",
      "  Resolved https://github.com/delta-incubator/deltatorch to commit 4346c313dc194b1222cbc799ce386776fd964120\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: deltalake>=0.10.0 in ./env/lib/python3.10/site-packages (from deltatorch==0.0.1) (0.10.0)\n",
      "Requirement already satisfied: evalidate>=1.1.0 in ./env/lib/python3.10/site-packages (from deltatorch==0.0.1) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.5 in ./env/lib/python3.10/site-packages (from deltatorch==0.0.1) (10.0.0)\n",
      "Requirement already satisfied: pyarrow>=7 in ./env/lib/python3.10/site-packages (from deltalake>=0.10.0->deltatorch==0.0.1) (12.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in ./env/lib/python3.10/site-packages (from pyarrow>=7->deltalake>=0.10.0->deltatorch==0.0.1) (1.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/delta-incubator/deltatorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/daniel.liden/git/delta-examples/env/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/daniel.liden/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/daniel.liden/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-9e882e8a-9d50-4348-9975-1be8001acebb;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 74ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-9e882e8a-9d50-4348-9975-1be8001acebb\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/2ms)\n",
      "23/07/20 08:06:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from delta import *\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"deltatorch-example\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some Data\n",
    "To provide an example with real data, we'll download the `mnist` dataset and save it as a Delta Lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from pyspark.sql.types import IntegerType, StructType, StructField, FloatType, BinaryType\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/20 08:06:43 WARN TaskSetManager: Stage 1 contains a task of very large size (3239 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/07/20 08:06:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/07/20 08:06:46 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "23/07/20 08:06:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    }
   ],
   "source": [
    "train_set = datasets.MNIST(root='./data', train=True, download=True)\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True)\n",
    "\n",
    "# Convert the data to a Spark DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"label\", FloatType(), False),\n",
    "    StructField(\"features\", BinaryType(), False)  # Changed ArrayType(IntegerType()) to BinaryType()\n",
    "])\n",
    "\n",
    "# Convert images to numpy arrays and save as binary\n",
    "train_data = [(i, float(y), bytearray(np.array(x))) for i, (x, y) in enumerate(train_set)]\n",
    "train_df = spark.createDataFrame(train_data, schema).repartition(50)\n",
    "\n",
    "test_data = [(i, float(y), bytearray(np.array(x))) for i, (x, y) in enumerate(test_set)]\n",
    "test_df = spark.createDataFrame(test_data, schema).repartition(50)\n",
    "\n",
    "# Write the DataFrame to Delta Lake format\n",
    "train_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(\"./data/mnist_delta/train\")\n",
    "test_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(\"./data/mnist_delta/test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reassure ourselves that we can retrieve the images and labels from the Delta Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/20 08:06:50 WARN TaskSetManager: Stage 38 contains a task of very large size (3239 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview one of the images\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Select one row from the DataFrame\n",
    "row = train_df.filter(train_df.id == 7).first()\n",
    "\n",
    "# Extract the image data and label\n",
    "image_data = row['features']\n",
    "label = row['label']\n",
    "\n",
    "# Convert the binary data back to a NumPy array and reshape it\n",
    "image_array = np.frombuffer(image_data, dtype=np.uint8).reshape(28, 28)\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(image_array, cmap='gray')\n",
    "plt.title(f'Label: {label}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a `DataLoader` from Delta Lake Tables\n",
    "We'll create a PyTorch `DataLoader` that reads data directly from the Delta Lake format using `deltatorch`. `deltatorch` creates an iterable dataset out of the delta tables, then wraps it with a PyTorch DataLoader to enable efficient, parallel data loading into a PyTorch model. This avoids the need to convert the full Delta Lake table to Pandas/NumPy before creating the DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deltatorch import create_pytorch_dataloader\n",
    "from deltatorch import FieldSpec\n",
    "from utils import BinaryToFloatTensor\n",
    "\n",
    "def create_data_loader(path:str, batch_size:int):\n",
    "    return create_pytorch_dataloader(\n",
    "        path,\n",
    "        id_field=\"id\",\n",
    "        fields=[\n",
    "            FieldSpec(\"features\", transform=BinaryToFloatTensor()),\n",
    "            FieldSpec(\"label\"),\n",
    "        ],\n",
    "        num_workers=4,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "train_dl = create_data_loader(\"./data/mnist_delta/train\", batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a `DataLoader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put the `deltatorch` `DataLoader` to work! We'll train a simple CNN on the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9977, Accuracy: 93.95%: : 1876it [00:31, 58.71it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss (Train): 0.5017, Accuracy (Train): 93.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.1571, Accuracy: 97.38%: : 1876it [00:31, 58.97it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss (Train): 0.1168, Accuracy (Train): 97.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the network architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(32 * 14 * 14, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(-1, 32 * 14 * 14)  # Flatten the tensor\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Create the network, loss function and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(2):  # Loop over the dataset multiple times\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    progress = tqdm(enumerate(train_dl), total=len(train_dl))\n",
    "    for i, data in progress:\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['features'], data['label']\n",
    "        inputs = inputs.unsqueeze(1).to(device)  # Add an extra dimension for the single channel (grayscale)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.long())  # Use long() to ensure the labels are of the correct type\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.long()).sum().item()\n",
    "\n",
    "        if (i + 1) % 100 == 0:  # Print training accuracy every 100 batches\n",
    "            acc = 100 * correct / total\n",
    "            progress.set_description(f\"Loss: {loss.item():.4f}, Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss (Train): {loss.item():.4f}, Accuracy (Train): {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we'll check the accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "316it [00:22, 14.35it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test accuracy: 97.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dl = create_data_loader(\"./data/mnist_delta/test\", batch_size=32)\n",
    "\n",
    "test_dl = create_data_loader(\"./data/mnist_delta/test\", batch_size=32)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(y_pred, y_test):\n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "    total = y_test.size(0)\n",
    "    correct = (predicted == y_test).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "total_accuracy = 0\n",
    "\n",
    "with torch.no_grad():  # We don't need gradients for evaluation\n",
    "    progress = tqdm(enumerate(test_dl), total=len(test_dl))\n",
    "    for i, data in progress:\n",
    "        inputs, labels = data['features'], data['label']\n",
    "        inputs = inputs.unsqueeze(1).to(device)  # Add an extra dimension for the single channel (grayscale)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        acc = calculate_accuracy(outputs, labels.long())  # Use long() to ensure the labels are of the correct type\n",
    "        total_accuracy += acc\n",
    "        \n",
    "        #progress.set_description(f\"Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "# Calculate average accuracy over the entire test set\n",
    "average_accuracy = total_accuracy / len(test_dl)\n",
    "\n",
    "print(f\"Average test accuracy: {average_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more examples, see the [examples directory in the deltatorch repository](https://github.com/delta-incubator/deltatorch/tree/main/examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

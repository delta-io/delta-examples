{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read emr cluster(j-3GWESRXJMF9D8) details\n",
      "Initiating EMR connection..\n",
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>2</td><td>application_1662658496356_0004</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-0-20-218.us-east-2.compute.internal:20888/proxy/application_1662658496356_0004/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-0-20-69.us-east-2.compute.internal:8042/node/containerlogs/container_1662658496356_0004_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "{\"namespace\": \"sagemaker-analytics\", \"cluster_id\": \"j-3GWESRXJMF9D8\", \"error_message\": null, \"success\": true, \"service\": \"emr\", \"operation\": \"connect\"}\n"
     ]
    }
   ],
   "source": [
    "%load_ext sagemaker_studio_analytics_extension.magics\n",
    "%sm_analytics emr connect --cluster-id j-3GWESRXJMF9D8 --auth-type None --language python  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Python Packages to Existing EMR Clusters\n",
    "\n",
    "## Notebook Scope Libraries\n",
    "Notebook-scoped libraries provide you the following benefits:\n",
    "\n",
    "* Runtime installation – You can import your favorite Python libraries from PyPI repositories and install them on your remote cluster (driver and executors) on the fly when you need them. These libraries are instantly available to your Spark runtime environment. There is no need to restart the notebook session or recreate your cluster.\n",
    "* Dependency isolation – The libraries you install using EMR Notebooks are isolated to your notebook session and don’t interfere with bootstrapped cluster libraries or libraries installed from other notebook sessions. These notebook-scoped libraries take precedence over bootstrapped libraries. Multiple notebook users can import their preferred version of the library and use it without dependency clashes on the same cluster.\n",
    "* Portable library environment – The library package installation happens from your notebook file. This allows you to recreate the library environment when you switch the notebook to a different cluster by re-executing the notebook code. At the end of the notebook session, the libraries you install through EMR Notebooks are automatically removed from the hosting EMR cluster.\n",
    "\n",
    "#### This functionality is available for clusters running EMR release >= 5.26.0. More info can be found in the [docs here](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-managed-notebooks-installing-libraries-and-kernels.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'name': 'sagemaker_studio_analytics_spark_session_49e2a08bdd6143c49d95910810101b51', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>application_1662658496356_0003</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-0-20-218.us-east-2.compute.internal:20888/proxy/application_1662658496356_0003/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-0-20-83.us-east-2.compute.internal:8042/node/containerlogs/container_1662658496356_0003_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>2</td><td>application_1662658496356_0004</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-0-20-218.us-east-2.compute.internal:20888/proxy/application_1662658496356_0004/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-0-20-69.us-east-2.compute.internal:8042/node/containerlogs/container_1662658496356_0004_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To enable notebook scoped libraries, we must set the configuration to use a virtualenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>3</td><td>application_1662658496356_0005</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-0-20-218.us-east-2.compute.internal:20888/proxy/application_1662658496356_0005/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-0-20-69.us-east-2.compute.internal:8042/node/containerlogs/container_1662658496356_0005_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.pyspark.python': 'python3', 'spark.pyspark.virtualenv.enabled': 'true', 'spark.pyspark.virtualenv.type': 'native', 'spark.pyspark.virtualenv.bin.path': '/usr/bin/virtualenv'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>application_1662658496356_0003</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-0-20-218.us-east-2.compute.internal:20888/proxy/application_1662658496356_0003/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-0-20-83.us-east-2.compute.internal:8042/node/containerlogs/container_1662658496356_0003_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3</td><td>application_1662658496356_0005</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-0-20-218.us-east-2.compute.internal:20888/proxy/application_1662658496356_0005/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-0-20-69.us-east-2.compute.internal:8042/node/containerlogs/container_1662658496356_0005_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{ \"conf\":{\n",
    "          \"spark.pyspark.python\": \"python3\",\n",
    "          \"spark.pyspark.virtualenv.enabled\": \"true\",\n",
    "          \"spark.pyspark.virtualenv.type\":\"native\",\n",
    "          \"spark.pyspark.virtualenv.bin.path\":\"/usr/bin/virtualenv\"\n",
    "         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                    Version\n",
      "-------------------------- ----------\n",
      "aws-cfn-bootstrap          2.0\n",
      "beautifulsoup4             4.9.3\n",
      "boto                       2.49.0\n",
      "boto3                      1.18.63\n",
      "botocore                   1.21.65\n",
      "certifi                    2022.6.15\n",
      "charset-normalizer         2.0.12\n",
      "click                      8.1.1\n",
      "cycler                     0.11.0\n",
      "Cython                     0.29.24\n",
      "distlib                    0.3.6\n",
      "docutils                   0.14\n",
      "filelock                   3.8.0\n",
      "idna                       3.3\n",
      "importlib-metadata         4.12.0\n",
      "jmespath                   0.10.0\n",
      "joblib                     1.1.0\n",
      "kiwisolver                 1.4.4\n",
      "lockfile                   0.11.0\n",
      "lxml                       4.8.0\n",
      "matplotlib                 3.4.3\n",
      "mysqlclient                1.4.2\n",
      "nltk                       3.7\n",
      "nose                       1.3.4\n",
      "numpy                      1.21.2\n",
      "pandas                     1.2.5\n",
      "Pillow                     9.2.0\n",
      "pip                        22.2.2\n",
      "platformdirs               2.5.2\n",
      "py-dateutil                2.2\n",
      "pyparsing                  3.0.9\n",
      "pystache                   0.5.4\n",
      "python-daemon              2.2.3\n",
      "python-dateutil            2.8.2\n",
      "python37-sagemaker-pyspark 1.4.1\n",
      "pytz                       2022.1\n",
      "PyYAML                     5.4.1\n",
      "regex                      2021.11.10\n",
      "requests                   2.26.0\n",
      "s3transfer                 0.5.2\n",
      "setuptools                 65.3.0\n",
      "simplejson                 3.2.0\n",
      "six                        1.13.0\n",
      "tqdm                       4.63.1\n",
      "typing_extensions          4.3.0\n",
      "urllib3                    1.26.12\n",
      "virtualenv                 20.16.5\n",
      "wheel                      0.37.1\n",
      "windmill                   1.6\n",
      "zipp                       3.8.1\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag."
     ]
    }
   ],
   "source": [
    "sc.list_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My work starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>6</td><td>application_1662658496356_0008</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-0-20-218.us-east-2.compute.internal:20888/proxy/application_1662658496356_0008/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-0-20-69.us-east-2.compute.internal:8042/node/containerlogs/container_1662658496356_0008_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.pyspark.python': 'python3', 'spark.pyspark.virtualenv.enabled': 'true', 'spark.pyspark.virtualenv.type': 'native', 'spark.pyspark.virtualenv.bin.path': '/usr/bin/virtualenv', 'spark.jars.packages': 'io.delta:delta-core_2.12:2.0.0', 'spark.sql.extensions': 'io.delta.sql.DeltaSparkSessionExtension', 'spark.sql.catalog.spark_catalog': 'org.apache.spark.sql.delta.catalog.DeltaCatalog'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>application_1662658496356_0003</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-0-20-218.us-east-2.compute.internal:20888/proxy/application_1662658496356_0003/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-0-20-83.us-east-2.compute.internal:8042/node/containerlogs/container_1662658496356_0003_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>6</td><td>application_1662658496356_0008</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-0-20-218.us-east-2.compute.internal:20888/proxy/application_1662658496356_0008/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-0-20-69.us-east-2.compute.internal:8042/node/containerlogs/container_1662658496356_0008_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f \n",
    "\n",
    "{\n",
    "  \"conf\": {\n",
    "    \"spark.pyspark.python\": \"python3\",\n",
    "    \"spark.pyspark.virtualenv.enabled\": \"true\",\n",
    "    \"spark.pyspark.virtualenv.type\":\"native\",\n",
    "    \"spark.pyspark.virtualenv.bin.path\":\"/usr/bin/virtualenv\",\n",
    "    \"spark.jars.packages\": \"io.delta:delta-core_2.12:2.0.0\",\n",
    "    \"spark.sql.extensions\": \"io.delta.sql.DeltaSparkSessionExtension\",\n",
    "    \"spark.sql.catalog.spark_catalog\": \"org.apache.spark.sql.delta.catalog.DeltaCatalog\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b647ebc390c48d8accf3ad08317da4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interrupted by user\n"
     ]
    }
   ],
   "source": [
    "# from delta.tables import *\n",
    "\n",
    "data = spark.read.csv(\"s3://vjain-dbx-bucket/nike-gt-poc/nike_product_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OG: Notice that there is no \"translate\" package available on our cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting translate\n",
      "  Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from translate) (2.26.0)\n",
      "Requirement already satisfied: click in /usr/local/lib64/python3.7/site-packages (from translate) (8.1.1)\n",
      "Collecting libretranslatepy==2.1.1\n",
      "  Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib64/python3.7/site-packages (from translate) (4.8.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from click->translate) (4.12.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->translate) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->translate) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->translate) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/site-packages (from requests->translate) (2.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/site-packages (from importlib-metadata->click->translate) (4.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata->click->translate) (3.8.1)\n",
      "Installing collected packages: libretranslatepy, translate\n",
      "Successfully installed libretranslatepy-2.1.1 translate-3.6.1\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag."
     ]
    }
   ],
   "source": [
    "# Install translate from given PyPI repository\n",
    "sc.install_pypi_package(\"translate\", \"https://pypi.org/simple\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from translate import Translator\n",
    "from pyspark.sql.functions import udf, col\n",
    "\n",
    "@udf\n",
    "def translate_to_german(sentence):\n",
    "    translator= Translator(to_lang=\"de\")\n",
    "    return translator.translate(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4979b01ef8435e84bcfcfb81517509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = [\"TaskID\",\"Sentence\"]\n",
    "data = [(\"1\", \"This is a pen\"),\n",
    "    (\"2\", \"This is a chair\")]\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=columns)\n",
    "\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(col(\"TaskID\"), \\\n",
    "    translate_to_german(col(\"Sentence\")).alias(\"Sentence\") ) \\\n",
    "   .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "SparkMagic PySpark (SparkAnalytics 1.0)",
   "language": "python",
   "name": "conda-env-sm_sparkmagic-pysparkkernel__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/sagemaker-sparkanalytics-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

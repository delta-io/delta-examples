{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83f111f0-e667-47bb-acd7-5525413db5ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: isodate 0.6.1\nNot uninstalling isodate at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e\nCan't uninstall 'isodate'. No files were found to uninstall.\nFound existing installation: soda 1.0.1\nUninstalling soda-1.0.1:\n  Successfully uninstalled soda-1.0.1\nFound existing installation: soda-freshness 0.0.3\nUninstalling soda-freshness-0.0.3:\n  Successfully uninstalled soda-freshness-0.0.3\nFound existing installation: soda-spark 1.0.1\nUninstalling soda-spark-1.0.1:\n  Successfully uninstalled soda-spark-1.0.1\nFound existing installation: soda-spark-df 1.0.1\nUninstalling soda-spark-df-1.0.1:\n  Successfully uninstalled soda-spark-df-1.0.1\n"
     ]
    }
   ],
   "source": [
    "pip freeze | grep soda | xargs pip uninstall -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8e1fb43-2e89-4e4f-a823-1398000b2668",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: https://pypi.cloud.soda.io\nCollecting soda-spark-df\n  Downloading https://pypi.cloud.soda.io/packages/soda_spark_df-1.0.1-py3-none-any.whl (3.0 kB)\nCollecting soda-spark==1.0.1\n  Downloading https://pypi.cloud.soda.io/packages/soda_spark-1.0.1-py3-none-any.whl (5.3 kB)\nRequirement already satisfied: pyspark in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from soda-spark-df) (3.4.0)\nCollecting soda==1.0.1\n  Downloading https://pypi.cloud.soda.io/packages/soda-1.0.1-py3-none-any.whl (221 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 221.6/221.6 kB 29.0 MB/s eta 0:00:00\nRequirement already satisfied: sqlparse~=0.4 in /databricks/python3/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (0.4.2)\nRequirement already satisfied: opentelemetry-api~=1.16.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (1.16.0)\nRequirement already satisfied: pandas<2.0.0,>=1.3.5 in /databricks/python3/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (1.4.4)\nRequirement already satisfied: inflect~=6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (6.0.4)\nRequirement already satisfied: requests~=2.27 in /databricks/python3/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (2.28.1)\nRequirement already satisfied: ia-questionary in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (1.10.0)\nCollecting soda-freshness<1.0.0\n  Downloading https://pypi.cloud.soda.io/packages/soda_freshness-0.0.3-py3-none-any.whl (4.3 kB)\nRequirement already satisfied: rich<14.0.0,>=13.3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (13.4.2)\nRequirement already satisfied: markupsafe<=2.1.1,>=2.0.1 in /databricks/python3/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (2.0.1)\nRequirement already satisfied: click~=8.0 in /databricks/python3/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (8.0.4)\nRequirement already satisfied: typer<1.0.0,>=0.7.0 in /databricks/python3/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (0.7.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-http~=1.16.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (1.16.0)\nRequirement already satisfied: pyyaml<6.0.0,>=5.4.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (5.4.1)\nRequirement already satisfied: segment-analytics-python<3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (2.2.3)\nRequirement already satisfied: pydantic<2.0.0,>=1.8.2 in /databricks/python3/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (1.10.7)\nRequirement already satisfied: ruamel.yaml<0.18.0,>=0.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (0.17.32)\nRequirement already satisfied: Jinja2<4.0,>=2.11 in /databricks/python3/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (2.11.3)\nRequirement already satisfied: antlr4-python3-runtime~=4.11.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (4.11.1)\nRequirement already satisfied: py4j==0.10.9.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from pyspark->soda-spark-df) (0.10.9.7)\nRequirement already satisfied: deprecated>=1.2.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from opentelemetry-api~=1.16.0->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (1.2.14)\nRequirement already satisfied: setuptools>=16.0 in /databricks/python3/lib/python3.10/site-packages (from opentelemetry-api~=1.16.0->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (63.4.1)\nRequirement already satisfied: backoff<3.0.0,>=1.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http~=1.16.0->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (2.2.1)\nRequirement already satisfied: opentelemetry-proto==1.16.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http~=1.16.0->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (1.16.0)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /databricks/python3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http~=1.16.0->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (1.56.4)\nRequirement already satisfied: opentelemetry-sdk~=1.16.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http~=1.16.0->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (1.16.0)\nRequirement already satisfied: protobuf<5.0,>=3.19 in /databricks/python3/lib/python3.10/site-packages (from opentelemetry-proto==1.16.0->opentelemetry-exporter-otlp-proto-http~=1.16.0->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (3.19.4)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.10/site-packages (from pandas<2.0.0,>=1.3.5->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas<2.0.0,>=1.3.5->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (2022.1)\nRequirement already satisfied: numpy>=1.21.0 in /databricks/python3/lib/python3.10/site-packages (from pandas<2.0.0,>=1.3.5->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (1.21.5)\nRequirement already satisfied: typing-extensions>=4.2.0 in /databricks/python3/lib/python3.10/site-packages (from pydantic<2.0.0,>=1.8.2->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (4.3.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests~=2.27->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests~=2.27->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (2022.9.14)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests~=2.27->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (1.26.11)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests~=2.27->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (3.3)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from rich<14.0.0,>=13.3.3->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (2.15.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from rich<14.0.0,>=13.3.3->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (3.0.0)\nRequirement already satisfied: ruamel.yaml.clib>=0.2.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from ruamel.yaml<0.18.0,>=0.17.0->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (0.2.7)\nRequirement already satisfied: monotonic~=1.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from segment-analytics-python<3.0.0->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (1.6)\nRequirement already satisfied: scipy<2.0.0,>=1.7.3 in /databricks/python3/lib/python3.10/site-packages (from soda-freshness<1.0.0->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (1.9.1)\nRequirement already satisfied: prompt_toolkit<=3.0.36,>=2.0 in /databricks/python3/lib/python3.10/site-packages (from ia-questionary->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (3.0.36)\nRequirement already satisfied: wrapt<2,>=1.10 in /databricks/python3/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api~=1.16.0->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (1.14.1)\nRequirement already satisfied: mdurl~=0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.3.3->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (0.1.2)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5b464307-594e-462d-89d9-bfbd0d87f02e/lib/python3.10/site-packages (from opentelemetry-sdk~=1.16.0->opentelemetry-exporter-otlp-proto-http~=1.16.0->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (0.37b0)\nRequirement already satisfied: wcwidth in /databricks/python3/lib/python3.10/site-packages (from prompt_toolkit<=3.0.36,>=2.0->ia-questionary->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (0.2.5)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=1.3.5->soda==1.0.1->soda-spark==1.0.1->soda-spark-df) (1.16.0)\nInstalling collected packages: soda-freshness, soda, soda-spark, soda-spark-df\nSuccessfully installed soda-1.0.1 soda-freshness-0.0.3 soda-spark-1.0.1 soda-spark-df-1.0.1\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pip install -i https://pypi.cloud.soda.io soda-spark-df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcf2af17-84f7-468e-93cd-1792ffd5fee8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Single-user check failed: user 'eric.kriner@soda.io' attempted to run a command on single-user cluster 0525-074349-70eqebqt, but the single user of this cluster is 'mathisse@soda.io'",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import Scan from Soda Library\n",
    "from soda.scan import Scan\n",
    "# Create a Spark DataFrame, or use the Spark API to read data and create a DataFrame\n",
    "df = spark.table(\"delta.`/databricks-datasets/nyctaxi/tables/nyctaxi_yellow`\")\n",
    "# Create a view that SodaCL uses as a dataset\n",
    "df.createOrReplaceTempView(\"NYC_Taxi_Data\")\n",
    "\n",
    "# Create a Scan object, set a scan definition, and attach a Spark session\n",
    "scan = Scan()\n",
    "scan.set_scan_definition_name(\"Databricks Notebook\")\n",
    "scan.set_data_source_name(\"spark_df\")\n",
    "scan.add_spark_session(spark)\n",
    "\n",
    "# Define checks for datasets\n",
    "# TODO: Extend checks for demo purposes\n",
    "checks = \"\"\"\n",
    "checks for NYC_Taxi_Data:\n",
    "  - row_count > 0:\n",
    "      name: Row Count Not Zero\n",
    "sample datasets:\n",
    "  datasets:\n",
    "    - include NYC_Taxi_Data\n",
    "\"\"\"\n",
    "# If you defined checks in a file accessible via Spark, you can use the scan.add_sodacl_yaml_file method to retrieve the checks\n",
    "scan.add_sodacl_yaml_str(checks)\n",
    "# Optionally, add a configuration file with Soda Cloud credentials\n",
    "config =\"\"\"\n",
    "soda_cloud:\n",
    "  host: demo.soda.io\n",
    "  api_key_id: 399b27f5-f51a-4463-9992-3ce241ab53c9\n",
    "  api_key_secret: hNSg7Fu4NngGVX--95RmdwIkpVpjVGrhr0cvVxpUPSQ4PD77xD_W1Q\n",
    "\"\"\"\n",
    "scan.add_configuration_yaml_str(config)\n",
    "# Execute a scan\n",
    "scan.execute()\n",
    "\n",
    "# Check the Scan object for methods to inspect the scan result; the following prints all logs to console\n",
    "print(scan.get_logs_text()) \n",
    "\n",
    "# Use the additional scan methods to insert circuit breakers into your processes, e.g. scan.assert_no_checks_fail"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Soda Library Demo",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
